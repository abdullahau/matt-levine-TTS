{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7495724c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, json\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import soundfile as sf\n",
    "from moviepy import ImageClip, AudioFileClip, concatenate_videoclips\n",
    "import textwrap\n",
    "\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "from kokoro import KPipeline\n",
    "import torch\n",
    "\n",
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('punkt_tab')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f402f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCREEN_SIZE = (720, 1280)\n",
    "FONT_SIZE = 45\n",
    "MIN_FONT_SIZE = 24\n",
    "FRAME_DIR = Path(\"video-resource/frames\"); FRAME_DIR.mkdir(exist_ok=True)\n",
    "AUDIO_DIR = Path(\"video-resource/audio\"); AUDIO_DIR.mkdir(exist_ok=True)\n",
    "OUTPUT_VIDEO = Path(\"video-resource/\")\n",
    "\n",
    "FONT_DIR = Path(\"video-resource/fonts\")\n",
    "FONTS = {\n",
    "    \"bold\": str(FONT_DIR / \"BearSansUI-Bold.otf\"),\n",
    "    \"italic\": str(FONT_DIR / \"BearSansUI-Italic.otf\"),\n",
    "    \"regular\": str(FONT_DIR / \"BearSansUI-Regular.otf\")\n",
    "}\n",
    "\n",
    "pipeline = KPipeline(lang_code=\"a\", repo_id=\"hexgrad/Kokoro-82M\")\n",
    "frame_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68609ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text):\n",
    "    \"\"\"Splits a block of text into a clean list of sentences.\"\"\"\n",
    "    if not text:\n",
    "        return []\n",
    "    paragraphs = re.split(r\"\\n{2,}\", text)\n",
    "    chunks = []\n",
    "    for para in paragraphs:\n",
    "        chunks.extend(sent_tokenize(para.strip()))\n",
    "    return [s.strip() for s in chunks if s.strip()]\n",
    "\n",
    "def wrap_text_by_pixels(draw, text, font, max_width):\n",
    "    \"\"\"Wraps text based on rendered pixel width to respect margins.\"\"\"\n",
    "    lines = []\n",
    "    words = text.split()\n",
    "    if not words:\n",
    "        return []\n",
    "\n",
    "    current_line = words[0]\n",
    "    for word in words[1:]:\n",
    "        if draw.textlength(current_line + \" \" + word, font=font) <= max_width:\n",
    "            current_line += \" \" + word\n",
    "        else:\n",
    "            lines.append(current_line)\n",
    "            current_line = word\n",
    "    lines.append(current_line)\n",
    "    return lines\n",
    "\n",
    "def create_text_image(header=None, subtitle=None, body=None):\n",
    "    \"\"\"\n",
    "    Creates an image with text. Dynamically adjusts body font size to fit.\n",
    "    \"\"\"\n",
    "    img = Image.new(\"RGB\", SCREEN_SIZE, \"white\")\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    padding = 80\n",
    "    max_width = SCREEN_SIZE[0] - 2 * padding\n",
    "    y_pos = padding\n",
    "    line_spacing = 10\n",
    "\n",
    "    # Draw Header\n",
    "    if header:\n",
    "        try:\n",
    "            font = ImageFont.truetype(FONTS[\"bold\"], int(FONT_SIZE * 1.2))\n",
    "        except IOError:\n",
    "            font = ImageFont.load_default()\n",
    "        lines = wrap_text_by_pixels(draw, header, font, max_width)\n",
    "        for line in lines:\n",
    "            draw.text((padding, y_pos), line, font=font, fill=\"black\")\n",
    "            y_pos += font.getbbox(line)[3] + line_spacing\n",
    "        y_pos += line_spacing # Extra space after header\n",
    "\n",
    "    # Draw Subtitle\n",
    "    if subtitle:\n",
    "        try:\n",
    "            font = ImageFont.truetype(FONTS[\"italic\"], FONT_SIZE)\n",
    "        except IOError:\n",
    "            font = ImageFont.load_default()\n",
    "        lines = wrap_text_by_pixels(draw, subtitle, font, max_width)\n",
    "        for line in lines:\n",
    "            draw.text((padding, y_pos), line, font=font, fill=\"gray\")\n",
    "            y_pos += font.getbbox(line)[3] + line_spacing\n",
    "        y_pos += line_spacing # Extra space after subtitle\n",
    "\n",
    "    # Draw Body with dynamic font sizing\n",
    "    if body:\n",
    "        body_top_y = y_pos\n",
    "        available_height = SCREEN_SIZE[1] - body_top_y - padding\n",
    "        current_font_size = FONT_SIZE\n",
    "\n",
    "        while current_font_size >= MIN_FONT_SIZE:\n",
    "            try:\n",
    "                body_font = ImageFont.truetype(FONTS[\"regular\"], current_font_size)\n",
    "            except IOError:\n",
    "                body_font = ImageFont.load_default()\n",
    "\n",
    "            body_lines = wrap_text_by_pixels(draw, body, body_font, max_width)\n",
    "            total_text_height = sum(body_font.getbbox(line)[3] + line_spacing for line in body_lines)\n",
    "\n",
    "            if total_text_height <= available_height:\n",
    "                break\n",
    "            else:\n",
    "                current_font_size -= 2\n",
    "        else:\n",
    "            print(f\"Warning: Text may be clipped as it exceeds available space even at min font size {MIN_FONT_SIZE}pt.\")\n",
    "\n",
    "\n",
    "        body_start_y = body_top_y + (available_height - total_text_height) / 2\n",
    "        for line in body_lines:\n",
    "            draw.text((padding, body_start_y), line, font=body_font, fill=\"black\")\n",
    "            body_start_y += body_font.getbbox(line)[3] + line_spacing\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def generate_audio_and_frame(text_to_speak, header=None, subtitle=None):\n",
    "    \"\"\"\n",
    "    Generates an audio file and a corresponding text frame.\n",
    "    Prevents header/subtitle text from being duplicated in the body.\n",
    "    \"\"\"\n",
    "    global frame_index\n",
    "    audio_path = AUDIO_DIR / f\"part_{frame_index:04}.wav\"\n",
    "\n",
    "    full_audio = []\n",
    "    text_for_image = \"\"\n",
    "    for gs, _, audio in pipeline(text_to_speak, voice=\"af_heart\", speed=1.0):\n",
    "        if audio is not None:\n",
    "            full_audio.append(audio)\n",
    "            text_for_image = gs\n",
    "    \n",
    "    if not full_audio:\n",
    "        print(f\"Warning: No audio generated for text: '{text_to_speak}'\")\n",
    "        return\n",
    "    \n",
    "    body_text = text_for_image\n",
    "    if text_for_image == header or text_for_image == subtitle:\n",
    "        body_text = None\n",
    "    \n",
    "    image = create_text_image(header=header, subtitle=subtitle, body=body_text)\n",
    "\n",
    "    image_path = FRAME_DIR / f\"frame_{frame_index:04}.png\"\n",
    "    image.save(image_path)\n",
    "\n",
    "    combined_audio = torch.cat(full_audio).unsqueeze(0)\n",
    "    sf.write(str(audio_path), combined_audio.squeeze().cpu().numpy(), 24000)\n",
    "\n",
    "    frame_index += 1\n",
    "\n",
    "def process_article(json_path):\n",
    "    \"\"\"\n",
    "    Processes a JSON article, generating audio and frames for each part sequentially.\n",
    "    \"\"\"\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        article = json.load(f)\n",
    "\n",
    "    main_title = article.get(\"title\", \"\")\n",
    "    subtitle = article.get(\"subtitle\", \"\")\n",
    "    sections = article.get(\"sections\", [])\n",
    "\n",
    "    for chunk in split_text(main_title):\n",
    "        generate_audio_and_frame(text_to_speak=chunk, header=chunk)\n",
    "\n",
    "    for chunk in split_text(subtitle):\n",
    "        generate_audio_and_frame(text_to_speak=chunk, header=main_title, subtitle=chunk)\n",
    "\n",
    "    for section in sections:\n",
    "        section_title = section.get(\"title\", \"\")\n",
    "        if section_title and section_title.lower() != main_title.lower():\n",
    "            for chunk in split_text(section_title):\n",
    "                generate_audio_and_frame(text_to_speak=chunk, header=section_title)\n",
    "\n",
    "        for para in section.get(\"content\", []):\n",
    "            for chunk in split_text(para):\n",
    "                # Use section_title as header, fallback to main_title\n",
    "                header = section_title if section_title.lower() != main_title.lower() else main_title\n",
    "                generate_audio_and_frame(text_to_speak=chunk, header=header)\n",
    "\n",
    "\n",
    "def render_video(title):\n",
    "    \"\"\"\n",
    "    Renders the final video by combining all generated frames and audio clips.\n",
    "    \"\"\"\n",
    "    clips = []\n",
    "    audio_files = sorted(AUDIO_DIR.glob(\"part_*.wav\"))\n",
    "    \n",
    "    if not audio_files:\n",
    "        print(\"No audio files found. Cannot render video.\")\n",
    "        return\n",
    "\n",
    "    for audio_file in audio_files:\n",
    "        idx = audio_file.stem.split(\"_\")[1]\n",
    "        image_file = FRAME_DIR / f\"frame_{idx}.png\"\n",
    "        \n",
    "        if not image_file.exists():\n",
    "            print(f\"Warning: Missing image file {image_file} for audio {audio_file}. Skipping clip.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            audio_info = sf.info(str(audio_file))\n",
    "            duration = audio_info.duration\n",
    "            if duration < 0.1: # Skip silent/too short clips\n",
    "                print(f\"Skipping very short clip: {audio_file}\")\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            print(f\"Could not read duration for {audio_file}: {e}. Setting to 2 seconds.\")\n",
    "            duration = 2\n",
    "\n",
    "        img_clip = ImageClip(str(image_file), duration=duration)\n",
    "        audio_clip = AudioFileClip(str(audio_file))\n",
    "        final_clip = img_clip.with_audio(audio_clip)\n",
    "        clips.append(final_clip)\n",
    "\n",
    "    if not clips:\n",
    "        print(\"No valid clips were created. Aborting video rendering.\")\n",
    "        return\n",
    "\n",
    "    final_video = concatenate_videoclips(clips, method=\"compose\")\n",
    "    final_video.write_videofile(OUTPUT_VIDEO / title, fps=24, audio_codec='aac', threads=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c67cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = \"video-resource/A Drug-Trial Stock Sale.json\"\n",
    "if os.path.exists(json_file):\n",
    "    process_article(json_file)\n",
    "    render_video(\"A Drug-Trial Stock Sale.mp4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Developer (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
