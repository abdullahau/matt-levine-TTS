{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7495724c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, json\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import soundfile as sf\n",
    "from moviepy import ImageClip, AudioFileClip, concatenate_videoclips\n",
    "import textwrap\n",
    "\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "from kokoro import KPipeline\n",
    "import torch\n",
    "\n",
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('punkt_tab')\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f402f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rehabnaeem/Developer/.venv/lib/python3.13/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\n",
      "/Users/rehabnaeem/Developer/.venv/lib/python3.13/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    }
   ],
   "source": [
    "SCREEN_SIZE = (720, 1280)\n",
    "FONT_SIZE = 45\n",
    "MIN_FONT_SIZE = 24\n",
    "FRAME_DIR = Path(\"video-resource/frames\"); FRAME_DIR.mkdir(exist_ok=True)\n",
    "AUDIO_DIR = Path(\"video-resource/audio\"); AUDIO_DIR.mkdir(exist_ok=True)\n",
    "OUTPUT_VIDEO = Path(\"video-resource/\")\n",
    "\n",
    "FONT_DIR = Path(\"video-resource/fonts\")\n",
    "FONTS = {\n",
    "    \"bold\": str(FONT_DIR / \"BearSansUI-Bold.otf\"),\n",
    "    \"italic\": str(FONT_DIR / \"BearSansUI-Italic.otf\"),\n",
    "    \"regular\": str(FONT_DIR / \"BearSansUI-Regular.otf\")\n",
    "}\n",
    "\n",
    "pipeline = KPipeline(lang_code=\"a\", repo_id=\"hexgrad/Kokoro-82M\")\n",
    "frame_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dba474e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text):\n",
    "    \"\"\"\n",
    "    Splits a block of text into a clean list of sentences,\n",
    "    intelligently handling numbered lists to keep them as single items.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return []\n",
    "    \n",
    "    numbered_list_pattern = re.compile(r\"^\\d+\\.\\s+\")\n",
    "    chunks = []\n",
    "    \n",
    "    for line in text.strip().split('\\n'):\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        if numbered_list_pattern.match(line):\n",
    "            chunks.append(line)\n",
    "        else:\n",
    "            chunks.extend(sent_tokenize(line))\n",
    "            \n",
    "    return [s.strip() for s in chunks if s.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "641ab723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_text_by_pixels(draw, text, font, max_width):\n",
    "    \"\"\"Wraps text based on rendered pixel width to respect margins.\"\"\"\n",
    "    lines = []\n",
    "    words = text.split()\n",
    "    if not words:\n",
    "        return []\n",
    "\n",
    "    current_line = words[0]\n",
    "    for word in words[1:]:\n",
    "        if draw.textlength(current_line + \" \" + word, font=font) <= max_width:\n",
    "            current_line += \" \" + word\n",
    "        else:\n",
    "            lines.append(current_line)\n",
    "            current_line = word\n",
    "    lines.append(current_line)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a71c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_image(header=None, subtitle=None, body=None, is_quote=False):\n",
    "    \"\"\"\n",
    "    Creates an image with text. Applies special styling for quotes.\n",
    "    \"\"\"\n",
    "    img = Image.new(\"RGB\", SCREEN_SIZE, \"white\")\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    padding = 80\n",
    "    max_width = SCREEN_SIZE[0] - 2 * padding\n",
    "    y_pos = padding\n",
    "    line_spacing = 10\n",
    "\n",
    "    if header:\n",
    "        try:\n",
    "            font = ImageFont.truetype(FONTS[\"bold\"], int(FONT_SIZE * 1.2))\n",
    "        except IOError:\n",
    "            font = ImageFont.load_default()\n",
    "        lines = wrap_text_by_pixels(draw, header, font, max_width)\n",
    "        for line in lines:\n",
    "            draw.text((padding, y_pos), line, font=font, fill=\"black\")\n",
    "            y_pos += font.getbbox(line)[3] + line_spacing\n",
    "        y_pos += line_spacing\n",
    "\n",
    "    if subtitle:\n",
    "        try:\n",
    "            font = ImageFont.truetype(FONTS[\"italic\"], FONT_SIZE)\n",
    "        except IOError:\n",
    "            font = ImageFont.load_default()\n",
    "        lines = wrap_text_by_pixels(draw, subtitle, font, max_width)\n",
    "        for line in lines:\n",
    "            draw.text((padding, y_pos), line, font=font, fill=\"gray\")\n",
    "            y_pos += font.getbbox(line)[3] + line_spacing\n",
    "        y_pos += line_spacing\n",
    "\n",
    "    if body:\n",
    "        body_top_y = y_pos\n",
    "        available_height = SCREEN_SIZE[1] - body_top_y - padding\n",
    "        current_font_size = FONT_SIZE\n",
    "\n",
    "        font_style = \"italic\" if is_quote else \"regular\"\n",
    "        \n",
    "        while current_font_size >= MIN_FONT_SIZE:\n",
    "            try:\n",
    "                body_font = ImageFont.truetype(FONTS[font_style], current_font_size)\n",
    "            except IOError:\n",
    "                body_font = ImageFont.load_default()\n",
    "\n",
    "            body_lines = wrap_text_by_pixels(draw, body, body_font, max_width)\n",
    "            total_text_height = sum(body_font.getbbox(line)[3] + line_spacing for line in body_lines) - line_spacing\n",
    "\n",
    "            if total_text_height <= available_height:\n",
    "                break\n",
    "            else:\n",
    "                current_font_size -= 2\n",
    "        else:\n",
    "            print(f\"Warning: Text may be clipped as it exceeds available space even at min font size {MIN_FONT_SIZE}pt.\")\n",
    "\n",
    "        body_start_y = body_top_y + (available_height - total_text_height) / 2\n",
    "        \n",
    "        if is_quote:\n",
    "            bar_width = 4\n",
    "            bar_padding = 20\n",
    "            bar_x0 = padding - bar_padding - bar_width\n",
    "            bar_x1 = padding - bar_padding\n",
    "            draw.rectangle([(bar_x0, body_start_y), (bar_x1, body_start_y + total_text_height)], fill=\"lightgray\")\n",
    "\n",
    "        for line in body_lines:\n",
    "            draw.text((padding, body_start_y), line, font=body_font, fill=\"black\")\n",
    "            body_start_y += body_font.getbbox(line)[3] + line_spacing\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51991191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_audio_and_frame(text_to_speak, header=None, subtitle=None, is_quote=False):\n",
    "    \"\"\"\n",
    "    Generates audio from the full text_to_speak, but strips markers for display.\n",
    "    \"\"\"\n",
    "    global frame_index\n",
    "    audio_path = AUDIO_DIR / f\"part_{frame_index:04}.wav\"\n",
    "\n",
    "    full_audio = []\n",
    "    for gs, _, audio in pipeline(text_to_speak, voice=\"af_heart\", speed=1.0):\n",
    "        if audio is not None:\n",
    "            full_audio.append(audio)\n",
    "            text_for_image = gs\n",
    "    \n",
    "    if not full_audio:\n",
    "        print(f\"Warning: No audio generated for text: '{text_to_speak}'\")\n",
    "        return\n",
    "    \n",
    "    display_text = text_for_image\n",
    "    if is_quote:\n",
    "        display_text = display_text.replace(\"Start quote.\", \"\").replace(\"End quote.\", \"\").strip()\n",
    "\n",
    "    if display_text == header or display_text == subtitle:\n",
    "        display_text = None\n",
    "    \n",
    "    image = create_text_image(header=header, subtitle=subtitle, body=display_text, is_quote=is_quote)\n",
    "\n",
    "    image_path = FRAME_DIR / f\"frame_{frame_index:04}.png\"\n",
    "    image.save(image_path)\n",
    "\n",
    "    combined_audio = torch.cat(full_audio).unsqueeze(0)\n",
    "    sf.write(str(audio_path), combined_audio.squeeze().cpu().numpy(), 24000)\n",
    "\n",
    "    frame_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d34c97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_article(json_path):\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        article = json.load(f)\n",
    "    main_title = article.get(\"title\", \"\")\n",
    "    subtitle = article.get(\"subtitle\", \"\")\n",
    "    sections = article.get(\"sections\", [])\n",
    "    \n",
    "    for chunk in split_text(main_title):\n",
    "        generate_audio_and_frame(text_to_speak=chunk, header=chunk)\n",
    "    for chunk in split_text(subtitle):\n",
    "        generate_audio_and_frame(text_to_speak=chunk, header=main_title, subtitle=chunk)\n",
    "\n",
    "    for section in sections:\n",
    "        section_title = section.get(\"title\", \"\")\n",
    "        header = section_title if section_title and section_title.lower() != main_title.lower() else main_title\n",
    "        \n",
    "        if section_title and section_title.lower() != main_title.lower():\n",
    "            for chunk in split_text(section_title):\n",
    "                generate_audio_and_frame(text_to_speak=chunk, header=chunk)\n",
    "\n",
    "        for para in section.get(\"content\", []):\n",
    "            if para.startswith(\"<start quote>\"):\n",
    "                quote_content = para.replace(\"<start quote>\", \"\").replace(\"<end quote>\", \"\").strip()\n",
    "                quote_sentences = split_text(quote_content)\n",
    "                if not quote_sentences:\n",
    "                    continue\n",
    "\n",
    "                if len(quote_sentences) == 1:\n",
    "                    sentence = quote_sentences[0]\n",
    "                    text_to_speak = f\"Start quote. {sentence} End quote.\"\n",
    "                    generate_audio_and_frame(text_to_speak=text_to_speak, header=header, is_quote=True)\n",
    "                else:\n",
    "                    generate_audio_and_frame(text_to_speak=f\"Start quote. {quote_sentences[0]}\", header=header, is_quote=True)\n",
    "                    for sentence in quote_sentences[1:-1]:\n",
    "                        generate_audio_and_frame(text_to_speak=sentence, header=header, is_quote=True)\n",
    "                    generate_audio_and_frame(text_to_speak=f\"{quote_sentences[-1]} End quote.\", header=header, is_quote=True)\n",
    "            else:\n",
    "                for chunk in split_text(para):\n",
    "                    generate_audio_and_frame(text_to_speak=chunk, header=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68609ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_video(title):\n",
    "    \"\"\"\n",
    "    Renders the final video by combining all generated frames and audio clips.\n",
    "    \"\"\"\n",
    "    clips = []\n",
    "    audio_files = sorted(AUDIO_DIR.glob(\"part_*.wav\"))\n",
    "    \n",
    "    if not audio_files:\n",
    "        print(\"No audio files found. Cannot render video.\")\n",
    "        return\n",
    "\n",
    "    for audio_file in audio_files:\n",
    "        idx = audio_file.stem.split(\"_\")[1]\n",
    "        image_file = FRAME_DIR / f\"frame_{idx}.png\"\n",
    "        \n",
    "        if not image_file.exists():\n",
    "            print(f\"Warning: Missing image file {image_file} for audio {audio_file}. Skipping clip.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            audio_info = sf.info(str(audio_file))\n",
    "            duration = audio_info.duration\n",
    "            if duration < 0.1: # Skip silent/too short clips\n",
    "                print(f\"Skipping very short clip: {audio_file}\")\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            print(f\"Could not read duration for {audio_file}: {e}. Setting to 2 seconds.\")\n",
    "            duration = 2\n",
    "\n",
    "        img_clip = ImageClip(str(image_file), duration=duration)\n",
    "        audio_clip = AudioFileClip(str(audio_file))\n",
    "        final_clip = img_clip.with_audio(audio_clip)\n",
    "        clips.append(final_clip)\n",
    "\n",
    "    if not clips:\n",
    "        print(\"No valid clips were created. Aborting video rendering.\")\n",
    "        return\n",
    "\n",
    "    final_video = concatenate_videoclips(clips, method=\"compose\")\n",
    "    output_path = os.path.join(OUTPUT_VIDEO, title) \n",
    "    final_video.write_videofile(\n",
    "        output_path, \n",
    "        fps=24, \n",
    "        codec='libx264',          \n",
    "        audio_codec='aac',        \n",
    "        audio_fps=24000,          \n",
    "        audio_bitrate=\"192k\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47c67cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Building video video-resource/A Drug-Trial Stock Sale.mp4.\n",
      "MoviePy - Writing audio in A Drug-Trial Stock SaleTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing video video-resource/A Drug-Trial Stock Sale.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready video-resource/A Drug-Trial Stock Sale.mp4\n"
     ]
    }
   ],
   "source": [
    "json_file = \"video-resource/A Drug-Trial Stock Sale.json\"\n",
    "process_article(json_file)\n",
    "render_video(\"A Drug-Trial Stock Sale.mp4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Developer (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
