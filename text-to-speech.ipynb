{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74a3aed5",
   "metadata": {},
   "source": [
    "## Newsletter Text-To-Speech - Kokoro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef74f767",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a85b6482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "import tempfile\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "from kokoro import KPipeline\n",
    "import torch\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304043c0",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7499d461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_audio_files(file_list, output_path):\n",
    "    \"\"\"\n",
    "    Combines a list of WAV files into a single output file.\n",
    "    \"\"\"\n",
    "    combined_data = []\n",
    "    for file_path in file_list:\n",
    "        data, sample_rate = sf.read(file_path)\n",
    "        if sample_rate != 24000:\n",
    "            continue\n",
    "        combined_data.append(data)\n",
    "    \n",
    "    final_audio = np.concatenate(combined_data)\n",
    "    sf.write(output_path, final_audio, 24000)\n",
    "\n",
    "def generate_speech(json_path, output_filename=\"final_audio.wav\", voice=\"af_heart\"):\n",
    "    \"\"\"\n",
    "    Processes a JSON article, letting Kokoro handle text chunking internally.\n",
    "    \n",
    "    Args:\n",
    "        json_path (str): Path to the input JSON file.\n",
    "        output_filename (str): Desired name for the final .wav file.\n",
    "        voice (str): The Kokoro voice to use.\n",
    "    \"\"\"\n",
    "    pipeline = KPipeline(lang_code=\"a\", repo_id=\"hexgrad/Kokoro-82M\")\n",
    "    \n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        article = json.load(f)\n",
    "    \n",
    "    all_text_blocks = []\n",
    "    \n",
    "    all_text_blocks.append(article.get(\"title\", \"\"))\n",
    "    all_text_blocks.append(article.get(\"subtitle\", \"\"))\n",
    "\n",
    "    for section in article.get(\"sections\", []):\n",
    "        section_title = section.get(\"title\", \"\")\n",
    "        if section_title and section_title.lower() != article.get(\"title\", \"\").lower():\n",
    "            all_text_blocks.append(section_title)\n",
    "\n",
    "        for para in section.get(\"content\", []):\n",
    "            if para.startswith(\"<start quote>\"):\n",
    "                quote_text = para.replace(\"<start quote>\", \"Start quote.\").replace(\"<end quote>\", \"End quote.\").strip()\n",
    "                all_text_blocks.append(quote_text)\n",
    "            else:\n",
    "                all_text_blocks.append(para)\n",
    "    \n",
    "    full_text_to_speak = \"\\n\\n\".join(block for block in all_text_blocks if block)\n",
    "    \n",
    "    if not full_text_to_speak:\n",
    "        return None\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        temp_dir_path = Path(temp_dir)\n",
    "        audio_part_paths = []\n",
    "        \n",
    "        generator = pipeline(full_text_to_speak, voice=voice, speed=1.0)\n",
    "        \n",
    "        for i, (text_chunk, _, audio_tensor) in enumerate(generator):\n",
    "            if audio_tensor is None or len(audio_tensor) == 0:\n",
    "                continue\n",
    "            \n",
    "            part_path = temp_dir_path / f\"part_{i:04d}.wav\"\n",
    "            sf.write(str(part_path), audio_tensor.numpy(), 24000)\n",
    "            audio_part_paths.append(str(part_path))\n",
    "\n",
    "        if not audio_part_paths:\n",
    "            return None\n",
    "        \n",
    "        combine_audio_files(audio_part_paths, output_filename)\n",
    "        return output_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2a1592",
   "metadata": {},
   "source": [
    "### Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f438d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = \"processed-json/Money Stuff - A Drug-Trial Stock Sale.json\"\n",
    "output_audio_file = \"Money Stuff - A Drug-Trial Stock Sal.wav\"\n",
    "\n",
    "result_path = generate_speech(text_file, output_filename=output_audio_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9fc9a5",
   "metadata": {},
   "source": [
    "### Convert All Processed `.json` Articles to Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e089ab8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = Path('processed-json/')\n",
    "\n",
    "if directory_path.is_dir():\n",
    "    for entry in directory_path.iterdir():\n",
    "        with open(entry, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "        final_audio_path = generate_speech(text, title=entry.stem)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Developer (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
