{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7495724c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, json, shutil\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import textwrap\n",
    "\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "from kokoro import KPipeline\n",
    "import torch\n",
    "\n",
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('punkt_tab')\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7c1837c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rehabnaeem/Developer/.venv/lib/python3.13/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\n",
      "/Users/rehabnaeem/Developer/.venv/lib/python3.13/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    }
   ],
   "source": [
    "SCREEN_SIZE = (720, 1280)\n",
    "FONT_SIZE = 45\n",
    "MIN_FONT_SIZE = 24\n",
    "FRAME_DIR = Path(\"video-resource/frames\")\n",
    "AUDIO_DIR = Path(\"video-resource/audio\")\n",
    "OUTPUT_VIDEO_DIR = Path(\"video-resource/output\")\n",
    "\n",
    "FRAME_DIR.mkdir(parents=True, exist_ok=True)\n",
    "AUDIO_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "FONT_DIR = Path(\"video-resource/fonts\")\n",
    "FONTS = {\n",
    "    \"bold\": str(FONT_DIR / \"BearSansUI-Bold.otf\"),\n",
    "    \"italic\": str(FONT_DIR / \"BearSansUI-Italic.otf\"),\n",
    "    \"regular\": str(FONT_DIR / \"BearSansUI-Regular.otf\")\n",
    "}\n",
    "\n",
    "def load_fonts(font_paths, size_range):\n",
    "    font_cache = {\"bold\": {}, \"italic\": {}, \"regular\": {}}\n",
    "    for style, path in font_paths.items():\n",
    "        for size in range(size_range[0], size_range[1] + 1):\n",
    "            try:\n",
    "                font_cache[style][size] = ImageFont.truetype(path, size)\n",
    "            except IOError:\n",
    "                font_cache[style][size] = ImageFont.load_default()\n",
    "    return font_cache\n",
    "FONT_CACHE = load_fonts(FONTS, (MIN_FONT_SIZE, FONT_SIZE + 10))\n",
    "\n",
    "pipeline = KPipeline(lang_code=\"a\", repo_id=\"hexgrad/Kokoro-82M\")\n",
    "frame_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17dffda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text):\n",
    "    if not text: return []\n",
    "    numbered_list_pattern = re.compile(r\"^\\d+\\.\\s+\")\n",
    "    chunks = []\n",
    "    for line in text.strip().split('\\n'):\n",
    "        line = line.strip()\n",
    "        if not line: continue\n",
    "        if numbered_list_pattern.match(line):\n",
    "            chunks.append(line)\n",
    "        else:\n",
    "            chunks.extend(sent_tokenize(line))\n",
    "    return [s.strip() for s in chunks if s.strip()]\n",
    "\n",
    "def chunk_long_text(text, threshold=220, max_length=200):\n",
    "    if len(text) <= threshold:\n",
    "        return [text]\n",
    "\n",
    "    chunks = textwrap.wrap(text, width=max_length, break_long_words=False, break_on_hyphens=False)\n",
    "    \n",
    "    if len(chunks) <= 1:\n",
    "        return chunks\n",
    "\n",
    "    modified_chunks = []\n",
    "    num_chunks = len(chunks)\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        if i > 0:\n",
    "            chunk = \"... \" + chunk\n",
    "        if i < num_chunks - 1:\n",
    "            chunk = chunk + \"...\"\n",
    "        modified_chunks.append(chunk)\n",
    "\n",
    "    return modified_chunks\n",
    "\n",
    "def wrap_text_by_pixels(draw, text, font, max_width):\n",
    "    lines = []\n",
    "    words = text.split()\n",
    "    if not words: return []\n",
    "    current_line = words[0]\n",
    "    for word in words[1:]:\n",
    "        if draw.textlength(current_line + \" \" + word, font=font) <= max_width:\n",
    "            current_line += \" \" + word\n",
    "        else:\n",
    "            lines.append(current_line)\n",
    "            current_line = word\n",
    "    lines.append(current_line)\n",
    "    return lines\n",
    "\n",
    "def pre_combine_audio(audio_dir, output_path):\n",
    "    audio_files = sorted(audio_dir.glob(\"part_*.wav\"))\n",
    "    if not audio_files:\n",
    "        return False\n",
    "        \n",
    "    combined_data = []\n",
    "    for file_path in audio_files:\n",
    "        data, sample_rate = sf.read(file_path)\n",
    "        if sample_rate != 24000:\n",
    "            continue\n",
    "        combined_data.append(data)\n",
    "    \n",
    "    master_audio_data = np.concatenate(combined_data)\n",
    "    sf.write(output_path, master_audio_data, 24000)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b01f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_image(header=None, subtitle=None, body=None, is_quote=False, is_summary=False):\n",
    "    img = Image.new(\"RGB\", SCREEN_SIZE, \"white\")\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    padding = 80\n",
    "    max_width = SCREEN_SIZE[0] - 2 * padding\n",
    "    y_pos = padding\n",
    "    line_spacing = 10\n",
    "\n",
    "    if header:\n",
    "        font = FONT_CACHE[\"bold\"].get(int(FONT_SIZE * 1.2), ImageFont.load_default())\n",
    "        for line in wrap_text_by_pixels(draw, header, font, max_width):\n",
    "            draw.text((padding, y_pos), line, font=font, fill=\"black\")\n",
    "            y_pos += font.getbbox(line)[3] + line_spacing\n",
    "        y_pos += line_spacing\n",
    "\n",
    "    if subtitle:\n",
    "        font = FONT_CACHE[\"italic\"].get(FONT_SIZE, ImageFont.load_default())\n",
    "        for line in wrap_text_by_pixels(draw, subtitle, font, max_width):\n",
    "            draw.text((padding, y_pos), line, font=font, fill=\"gray\")\n",
    "            y_pos += font.getbbox(line)[3] + line_spacing\n",
    "        y_pos += line_spacing\n",
    "\n",
    "    if body:\n",
    "        body_top_y = y_pos\n",
    "        available_height = SCREEN_SIZE[1] - body_top_y - padding\n",
    "        current_font_size = FONT_SIZE\n",
    "\n",
    "        font_style = \"regular\"\n",
    "        fill_color = \"black\"\n",
    "        if is_quote:\n",
    "            font_style = \"italic\"\n",
    "        elif is_summary:\n",
    "            font_style = \"italic\"\n",
    "            fill_color = \"gray\" \n",
    "        \n",
    "        while current_font_size >= MIN_FONT_SIZE:\n",
    "            body_font = FONT_CACHE[font_style].get(current_font_size, ImageFont.load_default())\n",
    "            body_lines = wrap_text_by_pixels(draw, body, body_font, max_width)\n",
    "            total_text_height = sum(body_font.getbbox(line)[3] + line_spacing for line in body_lines) - line_spacing\n",
    "            if total_text_height <= available_height:\n",
    "                break\n",
    "            else:\n",
    "                current_font_size -= 2\n",
    "        \n",
    "        body_start_y = body_top_y + (available_height - total_text_height) / 2\n",
    "        \n",
    "        if is_quote or is_summary:\n",
    "            bar_width = 4\n",
    "            bar_padding = 20\n",
    "            bar_x0 = padding - bar_padding - bar_width\n",
    "            bar_x1 = padding - bar_padding\n",
    "            draw.rectangle([(bar_x0, body_start_y), (bar_x1, body_start_y + total_text_height)], fill=\"lightgray\")\n",
    "\n",
    "        for line in body_lines:\n",
    "            draw.text((padding, body_start_y), line, font=body_font, fill=fill_color)\n",
    "            body_start_y += body_font.getbbox(line)[3] + line_spacing\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84119872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_audio_and_frame(text_to_speak, header=None, subtitle=None, is_quote=False, is_summary=False):\n",
    "    global frame_index\n",
    "    audio_path = AUDIO_DIR / f\"part_{frame_index:04d}.wav\"\n",
    "    full_audio, text_parts = [], []\n",
    "    \n",
    "    for gs, _, audio in pipeline(text_to_speak, voice=\"af_heart\", speed=1.0):\n",
    "        if audio is not None:\n",
    "            full_audio.append(audio)\n",
    "            text_parts.append(gs) \n",
    "    \n",
    "    if not full_audio:\n",
    "        print(f\"Warning: No audio generated for text: '{text_to_speak}'\")\n",
    "        return\n",
    "        \n",
    "    text_for_image = \"\".join(text_parts)\n",
    "    display_text = text_for_image\n",
    "    if is_quote:\n",
    "        display_text = display_text.replace(\"Start quote.\", \"\").replace(\"End quote.\", \"\").strip()\n",
    "\n",
    "    if not is_quote and not is_summary and (display_text == header or display_text == subtitle):\n",
    "        display_text = None\n",
    "    \n",
    "    image = create_text_image(header=header, subtitle=subtitle, body=display_text, is_quote=is_quote, is_summary=is_summary)\n",
    "    image_path = FRAME_DIR / f\"frame_{frame_index:04d}.png\"\n",
    "    image.save(image_path)\n",
    "\n",
    "    combined_audio = torch.cat(full_audio).unsqueeze(0)\n",
    "    sf.write(str(audio_path), combined_audio.squeeze().cpu().numpy(), 24000)\n",
    "    frame_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f743accf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_article(json_path):\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        article = json.load(f)\n",
    "    main_title = article.get(\"title\", \"\")\n",
    "    subtitle = article.get(\"subtitle\", \"\")\n",
    "    sections = article.get(\"sections\", [])\n",
    "    \n",
    "    for sentence in split_text(main_title):\n",
    "        for chunk in chunk_long_text(sentence):\n",
    "            generate_audio_and_frame(text_to_speak=chunk, header=chunk)\n",
    "\n",
    "    for sentence in split_text(subtitle):\n",
    "        for chunk in chunk_long_text(sentence):\n",
    "            generate_audio_and_frame(text_to_speak=chunk, header=main_title, subtitle=chunk)\n",
    "\n",
    "    for section in sections:\n",
    "        section_title = section.get(\"title\", \"\")\n",
    "        summary_text = section.get(\"summary\")\n",
    "        header = section_title if section_title and section_title.lower() != main_title.lower() else main_title\n",
    "        \n",
    "        if section_title and section_title.lower() != main_title.lower():\n",
    "            for sentence in split_text(section_title):\n",
    "                for chunk in chunk_long_text(sentence):\n",
    "                    generate_audio_and_frame(text_to_speak=chunk, header=chunk)\n",
    "\n",
    "        if summary_text:\n",
    "            for chunk in chunk_long_text(f\"Here is the summary of {section_title}:\"):\n",
    "                 generate_audio_and_frame(text_to_speak=chunk, header=header)\n",
    "            \n",
    "            for sentence in split_text(summary_text):\n",
    "                for chunk in chunk_long_text(sentence):\n",
    "                    generate_audio_and_frame(text_to_speak=chunk, header=header, is_summary=True)\n",
    "            \n",
    "            for chunk in chunk_long_text(\"End of Summary. Now reading the main article:\"):\n",
    "                generate_audio_and_frame(text_to_speak=chunk, header=header)\n",
    "        \n",
    "        for para in section.get(\"content\", []):\n",
    "            if para.startswith(\"<start quote>\"):\n",
    "                quote_content = para.replace(\"<start quote>\", \"\").replace(\"<end quote>\", \"\").strip()\n",
    "                quote_sentences = split_text(quote_content)\n",
    "                if not quote_sentences: continue\n",
    "\n",
    "                all_quote_display_chunks = []\n",
    "                for sentence in quote_sentences:\n",
    "                    all_quote_display_chunks.extend(chunk_long_text(sentence))\n",
    "\n",
    "                if not all_quote_display_chunks: continue\n",
    "                \n",
    "                if len(all_quote_display_chunks) == 1:\n",
    "                    text_to_speak = f\"Start quote. {all_quote_display_chunks[0]} End quote.\"\n",
    "                    generate_audio_and_frame(text_to_speak=text_to_speak, header=header, is_quote=True)\n",
    "                else:\n",
    "                    generate_audio_and_frame(text_to_speak=f\"Start quote. {all_quote_display_chunks[0]}\", header=header, is_quote=True)\n",
    "                    for chunk in all_quote_display_chunks[1:-1]:\n",
    "                        generate_audio_and_frame(text_to_speak=chunk, header=header, is_quote=True)\n",
    "                    generate_audio_and_frame(text_to_speak=f\"{all_quote_display_chunks[-1]} End quote.\", header=header, is_quote=True)\n",
    "            else:\n",
    "                for sentence in split_text(para):\n",
    "                    for chunk in chunk_long_text(sentence):\n",
    "                        generate_audio_and_frame(text_to_speak=chunk, header=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9041ee7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_video_with_ffmpeg(title, master_audio_path):    \n",
    "    filelist_path = FRAME_DIR / \"filelist.txt\"\n",
    "    with open(filelist_path, \"w\") as f:\n",
    "        audio_files = sorted(AUDIO_DIR.glob(\"part_*.wav\"))\n",
    "        for audio_file in audio_files:\n",
    "            idx = audio_file.stem.split(\"_\")[1]\n",
    "            image_file = FRAME_DIR / f\"frame_{idx}.png\"\n",
    "            if image_file.exists():\n",
    "                try:\n",
    "                    duration = sf.info(str(audio_file)).duration\n",
    "                    if duration < 0.01: continue\n",
    "                    f.write(f\"file '{image_file.resolve()}'\\n\")\n",
    "                    f.write(f\"duration {duration}\\n\")\n",
    "                except Exception:\n",
    "                    continue\n",
    "\n",
    "    output_path = OUTPUT_VIDEO_DIR / f\"{title}.mp4\"\n",
    "    \n",
    "    command = [\n",
    "        \"ffmpeg\",\n",
    "        \"-f\", \"concat\",\n",
    "        \"-safe\", \"0\",\n",
    "        \"-i\", str(filelist_path),\n",
    "        \"-i\", str(master_audio_path),\n",
    "        \"-c:v\", \"libx264\",\n",
    "        \"-pix_fmt\", \"yuv420p\",\n",
    "        \"-c:a\", \"copy\",\n",
    "        # \"-c:a\", \"aac\",\n",
    "        # \"-b:a\", \"320k\",\n",
    "        \"-shortest\",\n",
    "        \"-y\",\n",
    "        str(output_path)\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        result = subprocess.run(command, check=True, capture_output=True, text=True)\n",
    "        print(f\"\\n✅ FFMPEG rendering successful. Video saved to {output_path}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"❌ FFMPEG rendering failed.\")\n",
    "        print(\"FFMPEG stderr:\", e.stderr)\n",
    "    except FileNotFoundError:\n",
    "        print(\"❌ FFMPEG not found. Please ensure FFMPEG is installed and in your system's PATH.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60463728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ FFMPEG rendering successful. Video saved to video-resource/output/Money Stuff - A Drug-Trial Stock Sale.mp4\n"
     ]
    }
   ],
   "source": [
    "FRAME_DIR.mkdir(exist_ok=True)\n",
    "AUDIO_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "process_article(\"processed-json-with-summary/Money Stuff - A Drug-Trial Stock Sale.json\")\n",
    "master_audio_file = AUDIO_DIR / \"master_audio.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d356bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ FFMPEG rendering successful. Video saved to video-resource/output/Money Stuff - A Drug-Trial Stock Sale.mp4\n"
     ]
    }
   ],
   "source": [
    "if pre_combine_audio(AUDIO_DIR, master_audio_file):\n",
    "    render_video_with_ffmpeg(\"Money Stuff - A Drug-Trial Stock Sale\", master_audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd710cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = Path('processed-json-with-summary/')\n",
    "\n",
    "if directory_path.is_dir():\n",
    "    for entry in directory_path.iterdir():\n",
    "        FRAME_DIR.mkdir(exist_ok=True)\n",
    "        AUDIO_DIR.mkdir(exist_ok=True)\n",
    "        process_article(entry)\n",
    "        master_audio_file = AUDIO_DIR / \"master_audio.wav\"\n",
    "        if pre_combine_audio(AUDIO_DIR, master_audio_file):\n",
    "            render_video_with_ffmpeg(entry.stem, master_audio_file)\n",
    "        shutil.rmtree(\"video-resource/audio\")\n",
    "        shutil.rmtree(\"video-resource/frames\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796765fd",
   "metadata": {},
   "source": [
    "Updates:\n",
    "- Consider adding images from main article\n",
    "- Find a solution to the long pauses between broken down chunks of sentences.\n",
    "- Incorporate \"multiprocessing\" to accelerate processing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Developer (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
